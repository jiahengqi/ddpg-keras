{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Concatenate, Add, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import deque\n",
    "from utils import Memory\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENV_NAME='Pendulum-v0'\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self, env, sess, hidden_units=32,  \n",
    "                 tau=0.01, learning_rate=0.001):\n",
    "        self.env=env\n",
    "        self.sess=sess\n",
    "        K.set_session(sess)\n",
    "        self.tau=tau       \n",
    "        self.learning_rate=learning_rate\n",
    "        \n",
    "        self.model, self.states=self.create_actor(hidden_units, True)\n",
    "        self.target_model, _ = self.create_actor(hidden_units, False)\n",
    "        \n",
    "        self.action_grad=tf.placeholder(tf.float32, [None, self.env.action_space.shape[0]])\n",
    "        params_grad=tf.gradients(self.model.output, self.model.trainable_weights, -self.action_grad)\n",
    "        self.optimize=tf.train.AdamOptimizer(self.learning_rate).apply_gradients(zip(params_grad, self.model.trainable_weights))\n",
    "        \n",
    "    def create_actor(self, hidden_units, trainable=True):\n",
    "        s=Input(self.env.observation_space.shape)\n",
    "        h1=Dense(hidden_units, activation='relu',\n",
    "                 #kernel_initializer=initializers.truncated_normal(stddev=0.3),\n",
    "                 #bias_initializer=initializers.constant(0.01), #trainable=trainable\n",
    "               )(s)\n",
    "        h2=Dense(hidden_units, activation='relu',\n",
    "                 #kernel_initializer=initializers.truncated_normal(stddev=0.3),\n",
    "                 #bias_initializer=initializers.constant(0.01), #trainable=trainable\n",
    "               )(h1)\n",
    "        a=Dense(self.env.action_space.shape[0], activation='tanh',\n",
    "               #kernel_initializer=initializers.random_normal(stddev=0.3),\n",
    "                #bias_initializer=initializers.constant(0.01), #trainable=trainable\n",
    "               )(h2)\n",
    "        a0=Lambda(lambda x:x*2)(a)\n",
    "        model=Model(s, a0)\n",
    "        #model.compile(optimizer=Adam(lr=self.learning_rate), loss='mse')\n",
    "        return model, s\n",
    "    \n",
    "    def update_weights(self,):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(weights)):\n",
    "            target_weights[i] = self.tau * weights[i] + (1 - self.tau) * target_weights[i]\n",
    "        self.target_model.set_weights(target_weights)\n",
    "        \n",
    "    def train(self, s, grads):\n",
    "        #self.explore*=self.explore_decay\n",
    "        self.sess.run(self.optimize, feed_dict={self.states:s,self.action_grad:grads})\n",
    "        #self.sess.run(self.optimize, feed_dict={self.states:s, a, r, s_})\n",
    "        \n",
    "    def get_action(self, s, test_flag=False):\n",
    "        #a=self.model.predict(s)[0]*(self.env.action_space.high-self.env.action_space.low)+self.env.action_space.low\n",
    "        a=self.model.predict(s)[0]\n",
    "        #if test_flag:\n",
    "        return a\n",
    "        #return np.clip(np.random.normal(a, self.explore),-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic:\n",
    "    def __init__(self, env, sess, hidden_units=32, tau=0.1, learning_rate=0.01):\n",
    "        self.env=env\n",
    "        self.sess=sess\n",
    "        K.set_session(sess)\n",
    "        self.tau=tau\n",
    "        self.learning_rate=learning_rate\n",
    "        \n",
    "        self.model, self.states, self.actions = self.create_critic(hidden_units, True)\n",
    "        self.target_model, _, _ = self.create_critic(hidden_units, False) \n",
    "        self.qa_grads = tf.gradients(self.model.output, self.actions)[0]\n",
    "        \n",
    "    def create_critic(self, hidden_units, trainable=True):\n",
    "        s=Input(self.env.observation_space.shape)\n",
    "        h1=Dense(hidden_units, activation='relu',\n",
    "                 #kernel_initializer=initializers.truncated_normal(stddev=0.3), \n",
    "                 #bias_initializer=initializers.constant(0), #trainable=trainable\n",
    "                )(s)\n",
    "        h2=Dense(hidden_units, activation='linear',\n",
    "                 #kernel_initializer=initializers.truncated_normal(stddev=0.3), \n",
    "                 #bias_initializer=initializers.constant(0), #trainable=trainable\n",
    "                )(h1)\n",
    "        a=Input(self.env.action_space.shape)\n",
    "        h3=Dense(hidden_units, activation='linear',\n",
    "                 #kernel_initializer=initializers.truncated_normal(stddev=0.1), \n",
    "                 #use_bias=False, #trainable=trainable\n",
    "                )(a)\n",
    "        h4=Add()([h2, h3])\n",
    "        h5=Dense(hidden_units, activation='relu',)(h4)#这一层居然这么重要？\n",
    "        q=Dense(1,activation='linear',\n",
    "                #kernel_initializer=initializers.uniform(-0.01,0.01),\n",
    "               #bias_initializer=initializers.constant(0), #trainable=trainable\n",
    "               )(h5)\n",
    "        model=Model([s, a], q)\n",
    "        model.compile(optimizer=Adam(lr=self.learning_rate), loss='mse')\n",
    "        return model, s, a\n",
    "    \n",
    "    def get_grads(self, s, a):\n",
    "        return self.sess.run(self.qa_grads, feed_dict={self.states:s, self.actions:a})\n",
    "    \n",
    "    def update_weights(self,):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(weights)):\n",
    "            target_weights[i] = self.tau * weights[i] + (1 - self.tau) * target_weights[i]\n",
    "        self.target_model.set_weights(target_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG:\n",
    "    def __init__(self, env, batch_size=32, gamma=0.99, \n",
    "                 hidden_units=32, maxlen=10000, \n",
    "                 tau=0.1, actor_lr=0.001, critic_lr=0.001):\n",
    "        \n",
    "        self.env=env\n",
    "        self.batch_size=batch_size\n",
    "        self.gamma=gamma\n",
    "        self.maxlen=maxlen\n",
    "        \n",
    "        self.sess=tf.Session()\n",
    "           \n",
    "        \n",
    "        self.actor=Actor(env, self.sess, hidden_units, tau, actor_lr)\n",
    "        self.critic=Critic(env, self.sess, hidden_units, tau, critic_lr)\n",
    "        self.memory=Memory(maxlen)\n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        self.step=0\n",
    "        \n",
    "    def store(self, exp):\n",
    "        self.memory.add(exp)\n",
    "        \n",
    "    def update(self, ):\n",
    "        if len(self.memory.buffer)<1000:#self.batch_size:\n",
    "            return\n",
    "        \n",
    "        self.step+=1\n",
    "        \n",
    "        data = self.memory.sample(self.batch_size)\n",
    "        s=np.array([d[0] for d in data])\n",
    "        a=np.array([d[1] for d in data])\n",
    "        r=np.array([d[2] for d in data])\n",
    "        s_=np.array([d[3] for d in data])\n",
    "        \n",
    "        a_=self.actor.target_model.predict(s_)\n",
    "        target_q=self.critic.target_model.predict([s_, a_])\n",
    "        #y=np.array([d[2] for d in data])\n",
    "        #for i in range(self.batch_size):\n",
    "        #    y[i]+=self.gamma*target_q[i]\n",
    "        y=r[:,np.newaxis]+self.gamma*target_q   \n",
    "        self.critic.model.train_on_batch([s, a], y)\n",
    "        \n",
    "        action=self.actor.model.predict(s)     \n",
    "        grads=self.critic.get_grads(s, action)\n",
    "        self.actor.train(s,grads)\n",
    "        \n",
    "        if self.step%10==0:\n",
    "            self.actor.update_weights()\n",
    "            self.critic.update_weights()\n",
    "        \n",
    "        \n",
    "    def get_action(self, s):\n",
    "        return self.actor.get_action(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env=gym.make(ENV_NAME)#.unwrapped\n",
    "ddpg=DDPG(env,maxlen=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ou_noise(x, mu=0, theta=0.6, sigma=0.3):\n",
    "    return theta * (mu - x) + sigma * np.random.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore=1\n",
    "step=0\n",
    "for episodes in range(1000):\n",
    "    total=0\n",
    "    s=env.reset()\n",
    "    for step in range(200):\n",
    "        if explore>0:\n",
    "            explore-=1/2000\n",
    "            #explore*=0.9995\n",
    "        a=ddpg.get_action(s[np.newaxis,:])\n",
    "        #if episodes%10==0:\n",
    "        #    env.render()\n",
    "        #else:\n",
    "        #a=np.clip(np.random.normal(a, explore),-2,2)\n",
    "        #a=np.clip(a+(-1**np.random.randint(2))*explore,-2,2)\n",
    "        a=np.clip(a+ou_noise(a)*max(0,explore),-2,2)\n",
    "        s_, r, done, _ = env.step(a)\n",
    "        ddpg.store([s, a, r/10, s_])\n",
    "        ddpg.update()\n",
    "        s=s_\n",
    "        total+=r\n",
    "    print('%.2f'%explore,episodes,total)\n",
    "    #ddpg.actor.target_model.set_weights(ddpg.actor.model.get_weights())\n",
    "    #ddpg.critic.target_model.set_weights(ddpg.critic.model.get_weights())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
